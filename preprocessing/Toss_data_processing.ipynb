{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "20abd96a-4eb5-483d-b3d9-32e1c1340ece",
      "metadata": {
        "id": "20abd96a-4eb5-483d-b3d9-32e1c1340ece"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "E3rFd1hulQh6",
      "metadata": {
        "id": "E3rFd1hulQh6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95907c24-d2bc-4f34-86d5-5e6aa0e298d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path\n",
        "import json\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "MGYVFNfEl8RK"
      },
      "id": "MGYVFNfEl8RK",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = Path('/content/drive/MyDrive/toss/data')\n",
        "dataset_id = 'toss_ctr_v1'\n",
        "out_dir = data_dir / dataset_id\n",
        "out_dir.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "S57rW7lNuqTv"
      },
      "id": "S57rW7lNuqTv",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_train = pd.read_parquet(data_dir / 'train.parquet', engine='pyarrow')\n",
        "test_df = pd.read_parquet(data_dir / 'test.parquet', engine='pyarrow').drop(columns=['ID'], errors='ignore')\n",
        "\n",
        "print(\"Train shape:\", all_train.shape)\n",
        "print(\"Test shape:\", test_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpfYiJ48u3fH",
        "outputId": "8124f3dc-6c8e-4128-bf63-42a7c0dd28a6"
      },
      "id": "gpfYiJ48u3fH",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (10704179, 119)\n",
            "Test shape: (1527298, 118)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_col = 'clicked'\n",
        "pos = all_train[all_train[label_col] == 1]\n",
        "neg = all_train[all_train[label_col] == 0].sample(n=len(pos)*2, random_state=42)\n",
        "train_bal = pd.concat([pos, neg], axis=0).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "print(\"Balanced train shape:\", train_bal.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9p9NyAiu_F2",
        "outputId": "0d233ab5-4b81-4cc2-eb43-4401958c0831"
      },
      "id": "E9p9NyAiu_F2",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced train shape: (612537, 119)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, valid_df = train_test_split(\n",
        "    train_bal,\n",
        "    test_size=0.1,\n",
        "    random_state=42,\n",
        "    stratify=train_bal[label_col]\n",
        ")\n",
        "print(\"Train split shape:\", train_df.shape)\n",
        "print(\"Valid split shape:\", valid_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3koiV5NEvq0G",
        "outputId": "396276df-1adc-498b-81df-f6bd4fb36e5e"
      },
      "id": "3koiV5NEvq0G",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train split shape: (551283, 119)\n",
            "Valid split shape: (61254, 119)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exclude_cols = {'ID', 'seq'}\n",
        "\n",
        "for df in (train_df, valid_df, test_df):\n",
        "    drop_exist = [c for c in exclude_cols if c in df.columns]\n",
        "    if drop_exist:\n",
        "        df.drop(columns=drop_exist, inplace=True, errors='ignore')"
      ],
      "metadata": {
        "id": "EAhMZDsM2RHT"
      },
      "id": "EAhMZDsM2RHT",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def current_feature_cols(df_list, label):\n",
        "    cols = set()\n",
        "    for d in df_list:\n",
        "        cols |= set(d.columns)\n",
        "    cols = [c for c in sorted(cols) if c != label]\n",
        "    return cols\n",
        "\n",
        "feature_cols = current_feature_cols([train_df, valid_df, test_df], label_col)"
      ],
      "metadata": {
        "id": "WDAD4Qnc2VJT"
      },
      "id": "WDAD4Qnc2VJT",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_numeric(series: pd.Series) -> bool:\n",
        "    return pd.api.types.is_numeric_dtype(series)\n",
        "\n",
        "def infer_dtype(col: str) -> str:\n",
        "    for df in (train_df, valid_df, test_df):\n",
        "        if col in df.columns:\n",
        "            return 'numeric' if is_numeric(df[col]) else 'categorical'\n",
        "    return 'categorical'\n",
        "\n",
        "feat_types = {c: infer_dtype(c) for c in feature_cols}"
      ],
      "metadata": {
        "id": "AXv-RU582YY-"
      },
      "id": "AXv-RU582YY-",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(col: str):\n",
        "    uniques = set()\n",
        "    for df in (train_df, valid_df, test_df):\n",
        "        if col in df.columns:\n",
        "            vals = df[col].astype('string').fillna('<NA>').unique().tolist()\n",
        "            uniques.update(vals)\n",
        "    vocab = sorted(list(uniques))\n",
        "    return {v: i+1 for i, v in enumerate(vocab)}  # 0은 padding\n",
        "\n",
        "cat_mappings = {c: build_vocab(c) for c, t in feat_types.items() if t == 'categorical'}"
      ],
      "metadata": {
        "id": "VnlAtImj2aNJ"
      },
      "id": "VnlAtImj2aNJ",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_inplace(df: pd.DataFrame, has_label: bool):\n",
        "    if has_label and label_col in df.columns:\n",
        "        df[label_col] = pd.to_numeric(df[label_col], errors='coerce').fillna(0).astype('float32')\n",
        "    for c in feature_cols:\n",
        "        if feat_types[c] == 'categorical':\n",
        "            if c in df.columns:\n",
        "                df[c] = df[c].astype('string').fillna('<NA>').map(cat_mappings[c]).fillna(0).astype('int32')\n",
        "            else:\n",
        "                df[c] = np.int32(0)\n",
        "        else:\n",
        "            if c in df.columns:\n",
        "                df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0).astype('float32')\n",
        "            else:\n",
        "                df[c] = np.float32(0.0)\n",
        "    # 열 순서 고정\n",
        "    cols_order = [label_col] + feature_cols if has_label else feature_cols\n",
        "    return df[cols_order]\n",
        "\n",
        "train_enc = encode_inplace(train_df.copy(), has_label=True)\n",
        "valid_enc = encode_inplace(valid_df.copy(), has_label=True)\n",
        "test_enc  = encode_inplace(test_df.copy(),  has_label=False)"
      ],
      "metadata": {
        "id": "8TrahOzC2dpW"
      },
      "id": "8TrahOzC2dpW",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_enc.to_parquet(out_dir / 'train.parquet', index=False)\n",
        "valid_enc.to_parquet(out_dir / 'valid.parquet', index=False)\n",
        "test_enc.to_parquet(out_dir / 'test.parquet',  index=False)\n",
        "print(\"✔ 인코딩된 parquet 저장 완료:\", out_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYT_DRkk2Q-V",
        "outputId": "bed4b8f1-2759-452a-9658-bc779b562ba2"
      },
      "id": "AYT_DRkk2Q-V",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔ 인코딩된 parquet 저장 완료: /content/drive/MyDrive/toss/data/toss_ctr_v1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_parquet(out_dir / 'train.parquet', index=False)\n",
        "valid_df.to_parquet(out_dir / 'valid.parquet', index=False)\n",
        "test_df.to_parquet(out_dir / 'test.parquet', index=False)\n",
        "\n",
        "print(\"저장 완료:\", out_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5feGgXK8vtnL",
        "outputId": "dfc9486f-30ba-48a4-c188-62b4d4a3b42d"
      },
      "id": "5feGgXK8vtnL",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "저장 완료: /content/drive/MyDrive/toss/data/toss_ctr_v1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = []\n",
        "total_features = 0\n",
        "for c in feature_cols:\n",
        "    if feat_types[c] == 'categorical':\n",
        "        vocab_size = len(cat_mappings[c]) + 1  # padding 포함\n",
        "        features_list.append({\n",
        "            c: {\n",
        "                \"source\": \"\",\n",
        "                \"type\": \"categorical\",\n",
        "                \"padding_idx\": 0,\n",
        "                \"vocab_size\": int(vocab_size)\n",
        "            }\n",
        "        })\n",
        "        total_features += vocab_size\n",
        "    else:\n",
        "        features_list.append({\n",
        "            c: {\n",
        "                \"source\": \"\",\n",
        "                \"type\": \"numeric\"\n",
        "            }\n",
        "        })\n",
        "        # 구현 관례: numeric을 total_features에 +1로 집계(필요 시 이 한 줄 삭제)\n",
        "        total_features += 1\n",
        "\n",
        "feature_map = {\n",
        "    \"dataset_id\": dataset_id,\n",
        "    \"num_fields\": len(feature_cols),\n",
        "    \"total_features\": int(total_features),\n",
        "    \"input_length\": len(feature_cols),\n",
        "    \"labels\": [label_col],\n",
        "    \"features\": features_list\n",
        "}\n"
      ],
      "metadata": {
        "id": "R3CsoMvk2sWl"
      },
      "id": "R3CsoMvk2sWl",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(out_dir / 'feature_map.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(feature_map, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(\"✔ feature_map.json 저장 완료:\", out_dir / 'feature_map.json')\n",
        "print(\"   num_fields =\", feature_map['num_fields'],\n",
        "      \" total_features =\", feature_map['total_features'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPHndnLp2tGd",
        "outputId": "c48920c8-4e7a-4c09-bb83-f4ec661dcb80"
      },
      "id": "dPHndnLp2tGd",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔ feature_map.json 저장 완료: /content/drive/MyDrive/toss/data/toss_ctr_v1/feature_map.json\n",
            "   num_fields = 117  total_features = 178\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "gimin_py38",
      "language": "python",
      "name": "gimin_py38"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}